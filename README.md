### Hi there ðŸ‘‹

**Turning complex benchmark workflows into straightforward runs â€” thatâ€™s what we built MLCFlow and its automation for.**  
I co-develop the MLCFlow automation framework, streamlining benchmark submissions and reproducibility for both experienced participants and first-time users.

---

#### ðŸ”§ What I Do
In pursuit of making **MLPerf Inference** and **Automotive** benchmarking reproducible and hassle-free, I:
- Develop and maintain the **MLCFlow** automation framework.
- Integrate new benchmarks into automation pipelines as theyâ€™re released.
- Incorporate submittersâ€™ results post-submission for reproducibility testing.
- Maintain and enhance benchmark visualizers.
- Build test infrastructure to keep automation rock-solid as benchmarks evolve.

---

#### ðŸ“« Connect with Me
[![LinkedIn](https://img.shields.io/badge/Linked_In-0077B5?style=for-the-badge&logo=LinkedIn&logoColor=white)](https://www.linkedin.com/in/anandhu-s-2337661b7/)  
[![GitHub](https://img.shields.io/badge/GitHub-000000?style=for-the-badge&logo=GitHub&logoColor=white)](https://github.com/anandhu-eng)  
ðŸ“§ **anandhusooraj011@gmail.com**

---

#### ðŸ“Š Live Developer Metrics
![Metrics](https://raw.githubusercontent.com/anandhu-eng/anandhu-eng/main/github-metrics.svg)

